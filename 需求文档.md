参考当前项目源码，我想实现一个多智能体协同的demo，目的是一次对话既可以思考，也可以调动多个MCP或者tools

有个一主接口，接受用户的一个指令发送过来，在主线的接口里面不断地推送流式消息，如果有调用MCP、思考等，需要逐步输出到接口里面，类似于OpenManus
以下是其基本实现原理
```
多智能体系统
层次化设计：OpenManus 的智能体系统采用层次化设计，自底向上逐步增强功能。最底层是 BaseAgent，它定义了智能体的基础属性和基本行为，如状态管理、执行循环等。在其基础上，ReActAgent 实现了经典的“思考+行动”模式，每一步执行都分为 think 和 act 两个阶段。进一步的 ToolCallAgent，在 ReAct 基础上细化，使 think 阶段专注于工具选择，act 阶段负责执行所选工具。最顶层的 Manus 继承 ToolCallAgent，通过定制 system_prompt 和 available_tools 来赋予不同能力。
智能体协作：多个智能体可以根据任务需求进行协作，共同完成复杂的任务。例如，一个智能体负责任务规划，另一个智能体负责执行具体的工具调用，通过这种方式，能够更好地应对复杂多变的任务场景。
工具调用机制
工具层设计：工具模块是 OpenManus 的行动能力基础，各类工具均继承自 BaseTool。例如，PythonExecute 工具可以执行 Python 代码，GoogleSearch 工具用于网络搜索，BrowserUseTool 能够控制浏览器进行各种操作等。每个工具都有明确的名称、描述和参数规范，使 LLM 能够正确选择和使用它们。
工具与智能体的协作：智能体在执行任务时，会根据任务需求选择合适的工具进行调用。工具的调用是通过标准化的接口进行的，所有工具都通过 execute 方法调用，参数通过关键字参数传递，执行结果统一为字符串或特定的结果对象，便于智能体处理。
记忆系统
信息保存：OpenManus 使用 Memory 类来保存信息，它主要是一个消息列表的包装器，提供了添加、获取和清空消息的方法。记忆系统记录了用户输入、LLM 响应和工具执行结果，使智能体能够基于历史信息做出决策。
上下文管理：在任务执行过程中，记忆系统能够保持上下文连贯性，这对于智能体理解任务背景、跟踪任务进度以及做出合理的决策至关重要。
LLM 接口
与大语言模型通信：LLM 接口负责与大语言模型（如 OpenAI 的 GPT 模型）通信，封装了与 LLM API 的交互。它将智能体的记忆和工具信息传递给 LLM，并解析 LLM 的响应。
任务驱动：LLM 接口使得智能体能够利用大语言模型的强大语言理解和生成能力，更好地理解和执行用户任务。
流程控制
规划与执行：OpenManus 的 planning.py 实现了任务规划功能，能够将复杂任务拆解为多个可执行步骤，并管理任务计划状态。在任务执行过程中，系统会根据规划逐步执行各个步骤，并在每个步骤完成后进行结果汇总与状态更新。
动态调整：如果在执行过程中出现执行失败或结果异常，系统可以根据设计实现程度进行自动调试或重新规划。
```
请先帮我实现基本的需求文档，帮我规划前后端的传输协议格式等等，放在docs文件夹下面